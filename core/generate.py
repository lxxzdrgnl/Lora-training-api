"""
LoRA ëª¨ë¸ ì¶”ë¡  ëª¨ë“ˆ
"""

import torch
from diffusers import StableDiffusionPipeline
from peft import PeftModel
import argparse
from datetime import datetime
import os
from pathlib import Path

from .config import InferenceConfig


def load_pipeline(model_id: str, lora_path: str, device: str):
    """
    Stable Diffusion íŒŒì´í”„ë¼ì¸ + LoRA ë¡œë“œ

    Args:
        model_id: ë² ì´ìŠ¤ ëª¨ë¸ ID
        lora_path: LoRA ëª¨ë¸ ê²½ë¡œ
        device: ë””ë°”ì´ìŠ¤ (cuda/cpu)

    Returns:
        StableDiffusionPipeline: ë¡œë“œëœ íŒŒì´í”„ë¼ì¸
    """
    print(f"\nLoading base model: {model_id}")
    pipe = StableDiffusionPipeline.from_pretrained(
        model_id,
        torch_dtype=torch.float16,
        safety_checker=None
    )

    print(f"Loading LoRA weights: {lora_path}")
    pipe.unet = PeftModel.from_pretrained(
        pipe.unet,
        lora_path,
        torch_dtype=torch.float16
    )

    pipe.to(device)
    pipe.unet.eval()

    print("âœ… Model loaded successfully!\n")
    return pipe


def generate_images(
    lora_path: str,
    prompt: str = None,
    negative_prompt: str = None,
    num_images: int = 1,
    steps: int = 25,
    guidance_scale: float = 7.5,
    seed: int = None,
    output_dir: str = "outputs",
    config: InferenceConfig = None
):
    """
    ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (Modal APIìš©)

    Args:
        lora_path: LoRA ëª¨ë¸ ê²½ë¡œ
        prompt: í”„ë¡¬í”„íŠ¸
        negative_prompt: ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸
        num_images: ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜
        steps: ì¶”ë¡  ìŠ¤í…
        guidance_scale: CFG scale
        seed: ëœë¤ ì‹œë“œ
        output_dir: ì¶œë ¥ í´ë”
        config: ì¶”ë¡  ì„¤ì • (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)

    Returns:
        list: ìƒì„±ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    if config is None:
        config = InferenceConfig()

    # ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    if prompt:
        config.prompt = prompt
    if negative_prompt:
        config.negative_prompt = negative_prompt
    if lora_path:
        config.lora_path = lora_path

    config.num_images = num_images
    config.steps = steps
    config.guidance_scale = guidance_scale
    config.seed = seed
    config.output_dir = output_dir

    # íŒŒì´í”„ë¼ì¸ ë¡œë“œ
    pipe = load_pipeline(config.model_id, config.lora_path, config.device)

    # Trigger word ìë™ ì¶”ê°€
    if not config.prompt.startswith(config.trigger_word):
        full_prompt = f"{config.trigger_word}, {config.prompt}"
    else:
        full_prompt = config.prompt

    print("="*60)
    print(f"Generating {config.num_images} image(s)")
    print(f"Prompt: {full_prompt}")
    print(f"Negative: {config.negative_prompt}")
    print(f"Steps: {config.steps} | CFG Scale: {config.guidance_scale}")
    if config.seed is not None:
        print(f"Seed: {config.seed}")
    print("="*60)

    # ì‹œë“œ ì„¤ì •
    generator = None
    if config.seed is not None:
        generator = torch.Generator(device=config.device).manual_seed(config.seed)

    # ì¶œë ¥ í´ë” ìƒì„±
    output_dir = Path(config.output_dir)
    output_dir.mkdir(exist_ok=True)

    # ì´ë¯¸ì§€ ìƒì„±
    generated_files = []
    for i in range(config.num_images):
        print(f"\n[{i+1}/{config.num_images}] Generating...")

        with torch.no_grad():
            image = pipe(
                prompt=full_prompt,
                negative_prompt=config.negative_prompt,
                num_inference_steps=config.steps,
                guidance_scale=config.guidance_scale,
                generator=generator
            ).images[0]

        # íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{i+1}.png"
        output_path = output_dir / filename

        # ì €ì¥
        image.save(output_path)
        generated_files.append(str(output_path))
        print(f"âœ… Saved: {output_path}")

    print("\n" + "="*60)
    print(f"âœ… Successfully generated {len(generated_files)} image(s)")
    print(f"ğŸ“ Output folder: {config.output_dir}")
    print("="*60)

    return generated_files


def main():
    """CLI ì‹¤í–‰"""
    parser = argparse.ArgumentParser(
        description="í•™ìŠµëœ LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # í•„ìˆ˜ ì„¤ì •
    parser.add_argument(
        "--lora_path",
        type=str,
        default="my_lora_model",
        help="LoRA ëª¨ë¸ ê²½ë¡œ"
    )
    parser.add_argument(
        "--model_id",
        type=str,
        default="xyn-ai/anything-v4.0",
        help="ë² ì´ìŠ¤ Stable Diffusion ëª¨ë¸"
    )

    # í”„ë¡¬í”„íŠ¸ ì„¤ì •
    parser.add_argument(
        "--prompt",
        type=str,
        default="black hair, long hair, black and white manga style, monochrome illustration",
        help="ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸"
    )
    parser.add_argument(
        "--negative_prompt",
        type=str,
        default="color, colorful, low quality, blurry, ugly, distorted",
        help="ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸"
    )

    # ìƒì„± ì˜µì…˜
    parser.add_argument(
        "--num_images",
        type=int,
        default=1,
        help="ìƒì„±í•  ì´ë¯¸ì§€ ê°œìˆ˜"
    )
    parser.add_argument(
        "--steps",
        type=int,
        default=25,
        help="Inference steps (20-50 ê¶Œì¥)"
    )
    parser.add_argument(
        "--guidance_scale",
        type=float,
        default=7.5,
        help="CFG scale (7-10 ê¶Œì¥)"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=None,
        help="ëœë¤ ì‹œë“œ (ì¬í˜„ì„±)"
    )

    # ì¶œë ¥ ì„¤ì •
    parser.add_argument(
        "--output_dir",
        type=str,
        default="outputs",
        help="ìƒì„±ëœ ì´ë¯¸ì§€ ì €ì¥ í´ë”"
    )

    args = parser.parse_args()

    # LoRA ëª¨ë¸ ì¡´ì¬ í™•ì¸
    if not os.path.exists(args.lora_path):
        print(f"âŒ Error: LoRA model not found at {args.lora_path}")
        print(f"Please train the model first: python training.py")
        return

    # ì´ë¯¸ì§€ ìƒì„±
    config = InferenceConfig(
        model_id=args.model_id,
        lora_path=args.lora_path,
        prompt=args.prompt,
        negative_prompt=args.negative_prompt,
        num_images=args.num_images,
        steps=args.steps,
        guidance_scale=args.guidance_scale,
        seed=args.seed,
        output_dir=args.output_dir
    )

    generate_images(
        lora_path=config.lora_path,
        config=config
    )


if __name__ == "__main__":
    main()
