"""
VAE Latents ì‚¬ì „ ê³„ì‚° ëª¨ë“ˆ
í•™ìŠµ ì „ì— ëª¨ë“  ì´ë¯¸ì§€ë¥¼ VAEë¡œ ì¸ì½”ë”©í•˜ì—¬ ë””ìŠ¤í¬ì— ì €ì¥
"""

import torch
from diffusers import AutoencoderKL
from PIL import Image
import numpy as np
from pathlib import Path
from tqdm import tqdm
import os


def precompute_latents(
    dataset_path: str,
    output_path: str,
    model_id: str = "stablediffusionapi/anything-v5",
    device: str = "cuda",
    image_size: int = 512
):
    """
    ë°ì´í„°ì…‹ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ VAEë¡œ ì¸ì½”ë”©í•´ì„œ latentsë¡œ ì €ì¥

    Args:
        dataset_path: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í´ë” (clean dataset)
        output_path: latents ì €ì¥ í´ë”
        model_id: ë² ì´ìŠ¤ ëª¨ë¸ (í•™ìŠµì— ì‚¬ìš©í•  ê²ƒê³¼ ë™ì¼í•´ì•¼ í•¨)
        device: cuda/cpu
        image_size: ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ 512)

    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
    """
    print(f"\n{'='*60}")
    print("VAE Latents Precomputation")
    print(f"{'='*60}")
    print(f"Dataset: {dataset_path}")
    print(f"Output: {output_path}")
    print(f"Model: {model_id}")
    print(f"Device: {device}")

    # VAE ë¡œë“œ (í•™ìŠµì— ì‚¬ìš©í•  ê²ƒê³¼ ë™ì¼í•œ VAE)
    print(f"\nğŸ“¦ Loading VAE from {model_id}...")
    vae = AutoencoderKL.from_pretrained(
        model_id,
        subfolder="vae",
        torch_dtype=torch.float16
    ).to(device)
    vae.eval()
    vae.requires_grad_(False)
    print("âœ… VAE loaded")

    # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°
    dataset_dir = Path(dataset_path)
    image_files = list(dataset_dir.glob("*.png")) + list(dataset_dir.glob("*.jpg"))

    if len(image_files) == 0:
        raise ValueError(f"No images found in {dataset_path}")

    print(f"\nğŸ“‚ Found {len(image_files)} images")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path(output_path)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Latents ê³„ì‚° ë° ì €ì¥
    print(f"\nğŸ”„ Computing and saving latents...")

    success_count = 0
    total_size = 0

    for img_file in tqdm(image_files, desc="Precomputing latents"):
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
            img = Image.open(img_file).convert("RGB")
            img = img.resize((image_size, image_size), Image.LANCZOS)
            img_array = np.array(img).astype(np.float32) / 255.0
            img_array = (img_array - 0.5) / 0.5  # normalize to [-1, 1]
            pixel_values = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)
            pixel_values = pixel_values.to(device, dtype=torch.float16)

            # VAE encoding
            with torch.no_grad():
                latent = vae.encode(pixel_values).latent_dist.sample()
                latent = latent * vae.config.scaling_factor

            # ì €ì¥ (.pt íŒŒì¼ë¡œ)
            latent_file = output_dir / f"{img_file.stem}_latent.pt"
            torch.save(latent.cpu(), latent_file)

            # í†µê³„
            file_size = os.path.getsize(latent_file)
            total_size += file_size
            success_count += 1

        except Exception as e:
            print(f"\nâš ï¸ Failed to process {img_file.name}: {e}")
            continue

    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"âœ… Latents precomputation completed!")
    print(f"   Processed: {success_count}/{len(image_files)} images")
    print(f"   Total size: {total_size / 1024 / 1024:.2f} MB")
    print(f"   Avg size per latent: {total_size / success_count / 1024:.1f} KB")
    print(f"   Saved to: {output_path}")
    print(f"{'='*60}\n")

    return {
        "total": len(image_files),
        "success": success_count,
        "total_size_mb": total_size / 1024 / 1024,
        "output_dir": str(output_dir)
    }


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Precompute VAE latents for LoRA training")
    parser.add_argument("--dataset_path", type=str, required=True, help="Path to clean dataset")
    parser.add_argument("--output_path", type=str, required=True, help="Path to save latents")
    parser.add_argument("--model_id", type=str, default="stablediffusionapi/anything-v5")
    parser.add_argument("--device", type=str, default="cuda")

    args = parser.parse_args()

    precompute_latents(
        dataset_path=args.dataset_path,
        output_path=args.output_path,
        model_id=args.model_id,
        device=args.device
    )
