"""
LoRA ëª¨ë¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµëœ LoRA ê°€ì¤‘ì¹˜ë¡œ ì´ë¯¸ì§€ ìƒì„±
"""

import torch
from diffusers import StableDiffusionPipeline
from peft import PeftModel
import argparse
from datetime import datetime
import os
from pathlib import Path


def load_pipeline(model_id, lora_path, device):
    """Stable Diffusion íŒŒì´í”„ë¼ì¸ + LoRA ë¡œë“œ"""
    print(f"\nLoading base model: {model_id}")
    pipe = StableDiffusionPipeline.from_pretrained(
        model_id,
        torch_dtype=torch.float16,
        safety_checker=None
    )

    print(f"Loading LoRA weights: {lora_path}")
    pipe.unet = PeftModel.from_pretrained(
        pipe.unet,
        lora_path,
        torch_dtype=torch.float16
    )

    pipe.to(device)
    pipe.unet.eval()

    print("âœ… Model loaded successfully!\n")
    return pipe


def generate_images(pipe, args, device):
    """ì´ë¯¸ì§€ ìƒì„±"""
    # Trigger word ìë™ ì¶”ê°€
    if not args.prompt.startswith("sks"):
        full_prompt = f"sks girl, {args.prompt}"
    else:
        full_prompt = args.prompt

    print("="*60)
    print(f"Generating {args.num_images} image(s)")
    print(f"Prompt: {full_prompt}")
    print(f"Negative: {args.negative_prompt}")
    print(f"Steps: {args.steps} | CFG Scale: {args.guidance_scale}")
    if args.seed is not None:
        print(f"Seed: {args.seed}")
    print("="*60)

    # ì‹œë“œ ì„¤ì •
    generator = None
    if args.seed is not None:
        generator = torch.Generator(device=device).manual_seed(args.seed)

    # ì¶œë ¥ í´ë” ìƒì„±
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)

    # ì´ë¯¸ì§€ ìƒì„±
    generated_files = []
    for i in range(args.num_images):
        print(f"\n[{i+1}/{args.num_images}] Generating...")

        with torch.no_grad():
            image = pipe(
                prompt=full_prompt,
                negative_prompt=args.negative_prompt,
                num_inference_steps=args.steps,
                guidance_scale=args.guidance_scale,
                generator=generator
            ).images[0]

        # íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{i+1}.png"
        output_path = output_dir / filename

        # ì €ì¥
        image.save(output_path)
        generated_files.append(output_path)
        print(f"âœ… Saved: {output_path}")

    return generated_files


def main():
    # í™˜ê²½ ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Device: {device}")

    # ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(
        description="í•™ìŠµëœ LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # í•„ìˆ˜ ì„¤ì •
    parser.add_argument(
        "--lora_path",
        type=str,
        default="my_lora_model",
        help="LoRA ëª¨ë¸ ê²½ë¡œ"
    )
    parser.add_argument(
        "--model_id",
        type=str,
        default="xyn-ai/anything-v4.0",
        help="ë² ì´ìŠ¤ Stable Diffusion ëª¨ë¸"
    )

    # í”„ë¡¬í”„íŠ¸ ì„¤ì •
    parser.add_argument(
        "--prompt",
        type=str,
        default="black hair, long hair, black and white manga style, monochrome illustration",
        help="ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸"
    )
    parser.add_argument(
        "--negative_prompt",
        type=str,
        default="color, colorful, low quality, blurry, ugly, distorted",
        help="ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸"
    )

    # ìƒì„± ì˜µì…˜
    parser.add_argument(
        "--num_images",
        type=int,
        default=1,
        help="ìƒì„±í•  ì´ë¯¸ì§€ ê°œìˆ˜"
    )
    parser.add_argument(
        "--steps",
        type=int,
        default=25,
        help="Inference steps (20-50 ê¶Œì¥)"
    )
    parser.add_argument(
        "--guidance_scale",
        type=float,
        default=7.5,
        help="CFG scale (7-10 ê¶Œì¥)"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=None,
        help="ëœë¤ ì‹œë“œ (ì¬í˜„ì„±)"
    )

    # ì¶œë ¥ ì„¤ì •
    parser.add_argument(
        "--output_dir",
        type=str,
        default="outputs",
        help="ìƒì„±ëœ ì´ë¯¸ì§€ ì €ì¥ í´ë”"
    )

    args = parser.parse_args()

    # LoRA ëª¨ë¸ ì¡´ì¬ í™•ì¸
    if not os.path.exists(args.lora_path):
        print(f"âŒ Error: LoRA model not found at {args.lora_path}")
        print(f"Please train the model first: python train.py")
        return

    # íŒŒì´í”„ë¼ì¸ ë¡œë“œ
    pipe = load_pipeline(args.model_id, args.lora_path, device)

    # ì´ë¯¸ì§€ ìƒì„±
    generated_files = generate_images(pipe, args, device)

    # ì™„ë£Œ ë©”ì‹œì§€
    print("\n" + "="*60)
    print(f"âœ… Successfully generated {len(generated_files)} image(s)")
    print(f"ğŸ“ Output folder: {args.output_dir}")
    print("="*60)


if __name__ == "__main__":
    main()
